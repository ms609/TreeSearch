% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/Information.R
\name{SplitEntropy}
\alias{SplitEntropy}
\title{Entropy of two splits}
\usage{
SplitEntropy(split1, split2 = split1)
}
\arguments{
\item{split1, split2}{Logical vectors listing terminals in same order, such that
each terminal is identified as a member of the ingroup (`TRUE`) or outgroup 
(`FALSE`) of the respective bipartition split.}
}
\value{
A numeric vector listing, in bits,
 * `h1` The entropy of split 1
 * `h1` The entropy of split 2
 * `jointH` The joint entropy of both splits
 * `i` The mutual information of the splits
 * `vI` The variation of information of the splits (see Meila 2007)
}
\description{
Reports various values pertaining to the information content of two splits,
treating splits as subdivisions of _n_ terminals into two clusters.
}
\references{
\insertRef{Meila2007}{TreeSearch}
}
\author{
Martin R. Smith
}
